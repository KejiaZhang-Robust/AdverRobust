import torch.backends.cudnn as cudnn

from models import *
from utils_test_transfer import evaluate_pgd, test_adv_auto, evaluate_normal, evaluate_cw
from easydict import EasyDict
import yaml
import os
import logging


from utils import *

device = 'cuda' if torch.cuda.is_available() else 'cpu'

with open('configs_test_transfer.yml') as f:
    config = EasyDict(yaml.load(f,Loader=yaml.FullLoader))

#TODO: Model generate the atack
net = WRN34_10(Num_class=config.DATA.num_class)
#TODO: Model defense the atack
test_net = ResNet18(Num_class=config.DATA.num_class)

data_set = config.DATA.Data
file_name_generate = config.Operation.Prefix_generate
file_name_test = config.Operation.Prefix_test
check_path_generate = os.path.join('./checkpoint',data_set, file_name_generate)
check_path_test = os.path.join('./checkpoint', data_set, file_name_test)
record_path = os.path.join(check_path_test, file_name_generate+config.Operation.Record_string+'_record.txt')

logger = logging.getLogger(__name__)
logging.basicConfig(
    format='[%(asctime)s] - %(message)s',
    datefmt='%Y/%m/%d %H:%M:%S',
    level=logging.DEBUG,
    handlers=[
        logging.FileHandler(os.path.join(check_path_test, file_name_generate + 'transfer_test.log')),
        logging.StreamHandler()
    ])
logger.info(config.Operation.Record_string)

_, test_loader = create_dataloader(data_set, Norm=False)

net.num_classes = config.DATA.num_class
norm_mean = torch.tensor(config.DATA.mean).to(device)
norm_std = torch.tensor(config.DATA.std).to(device)
net.norm = True
net.mean = norm_mean
net.std = norm_std
test_net.num_classes = config.DATA.num_class
test_net.norm = True
test_net.mean = norm_mean
test_net.std = norm_std

net = net.to(device)
net = torch.nn.DataParallel(net)  # parallel GPU
test_net = test_net.to(device)
test_net = torch.nn.DataParallel(test_net)
cudnn.benchmark = True

logger.info(config.Operation.Addtional_string+"\n=====Adversarial Attack Performance=====:\n"+"Adversarial Examples are generated by: "+ file_name_generate+ "||     Adversarial Defense are operated by:"+file_name_test+'\n')

#TODO: PGD Attack test
print("==> Loading model:"+file_name_generate+"\n")
assert os.path.isdir(check_path_generate), 'Error: no generate model checkpoint directory found!'
print("==> Loading model:"+file_name_test+"\n")
assert os.path.isdir(check_path_test), 'Error: no test model checkpoint directory found!'
checkpoint_best_generate = torch.load(os.path.join(check_path_generate, 'model_best.pth.tar'))
checkpoint_last_generate = torch.load(os.path.join(check_path_generate, 'checkpoint.pth.tar'))
checkpoint_best_test = torch.load(os.path.join(check_path_test, 'model_best.pth.tar'))
checkpoint_last_test = torch.load(os.path.join(check_path_test, 'checkpoint.pth.tar'))

# ['apgd-ce', 'apgd-t', 'fab-t', 'square']
auto_attacks_methods = ['apgd-ce', 'apgd-t', 'fab-t', 'square']
if config.Operation.Validate_Best == True:
    logger.info("=======Best_trained_model Performance=======\n")
    net.load_state_dict(checkpoint_best_generate['state_dict'])
    test_net.load_state_dict(checkpoint_best_test['state_dict'])
    if config.Operation.Validate_Natural:
        ##----->Clean
        clean_acc = evaluate_normal(test_net, test_loader)
        logger.info(f"Normal Acc: {clean_acc:.2f}\n")
    if config.Operation.Validate_PGD:
        ##----->FGSM
        fgsm_acc = evaluate_pgd(net, test_net, test_loader, config.ADV.clip_eps, config.ADV.fgsm_step, 1)
        logger.info( f"FGSM_attack:[eps:{config.ADV.clip_eps},step_size:{config.ADV.fgsm_step}]->fgsm_acc: {fgsm_acc: .2f}" + "\n")
        ##----->PDG
        for pgd_param in config.ADV.pgd_test:
            pgd_acc = evaluate_pgd(net, test_net, test_loader, pgd_param[1], pgd_param[2], pgd_param[0])
            logger.info(f"PGD_attack:[nb_iter:{pgd_param[0]},eps:{pgd_param[1]},step_size:{pgd_param[2]}]->pgd_acc: {pgd_acc: .2f}" + "\n")
    if config.Operation.Validate_CW:
        ##----->CW
        pgd_acc = evaluate_cw(net, test_net, test_loader, config.ADV.clip_eps, config.ADV.fgsm_step, config.ADV.iter)
        logger.info(f"CW_attack:[nb_iter:{config.ADV.iter},eps:{config.ADV.clip_eps},step_size:{config.ADV.fgsm_step}]->cw_acc: {pgd_acc: .2f}" + "\n")
    if config.Operation.Validate_Autoattack:
        ##----->Autoattack
        auto_acc = test_adv_auto(net, test_net, test_loader, config.ADV.clip_eps, auto_attacks_methods)
        logger.info(f"Auto_attack:[eps:{config.ADV.clip_eps},step_size:{config.ADV.fgsm_step}]->pgd_acc: {auto_acc: .2f}" + "\n")

if config.Operation.Validate_Last == True:
    logger.info("=======Last_trained_model Performance=======\n")
    net.load_state_dict(checkpoint_last_generate['state_dict'])
    test_net.load_state_dict(checkpoint_last_test['state_dict'])
    if config.Operation.Validate_Natural:
        ##----->Clean
        clean_acc = evaluate_normal(test_net, test_loader)
        logger.info(f"Normal Acc: {clean_acc:.2f}\n")
    if config.Operation.Validate_PGD:
        ##----->FGSM
        fgsm_acc = evaluate_pgd(net, test_net, test_loader, config.ADV.clip_eps, config.ADV.fgsm_step, 1)
        logger.info(f"FGSM_attack:[eps:{config.ADV.clip_eps},step_size:{config.ADV.fgsm_step}]->fgsm_acc: {fgsm_acc: .2f}" + "\n")
        ##----->PDG
        for pgd_param in config.ADV.pgd_test:
            pgd_acc = evaluate_pgd(net, test_net, test_loader, pgd_param[1], pgd_param[2], pgd_param[0])
            logger.info(f"PGD_attack:[nb_iter:{pgd_param[0]},eps:{pgd_param[1]},step_size:{pgd_param[2]}]->pgd_acc: {pgd_acc: .2f}" + "\n")
    if config.Operation.Validate_CW:
        ##----->CW
        pgd_acc = evaluate_cw(net, test_net, test_loader, config.ADV.clip_eps, config.ADV.fgsm_step, config.ADV.iter)
        logger.info(f"CW_attack:[nb_iter:{config.ADV.iter},eps:{config.ADV.clip_eps},step_size:{config.ADV.fgsm_step}]->cw_acc: {pgd_acc: .2f}" + "\n")
    if config.Operation.Validate_Autoattack:
        ##----->Autoattack
        auto_acc = test_adv_auto(net, test_net, test_loader, config.ADV.clip_eps, auto_attacks_methods)
        logger.info(f"Auto_attack:[eps:{config.ADV.clip_eps},step_size:{config.ADV.fgsm_step}]->pgd_acc: {auto_acc: .2f}" + "\n")